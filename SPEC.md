### **提案：LLMデータ分析ツール仕様**

#### **1. 概要**

本ツールは、大規模なテキストファイル（プレーンテキスト、JSONLなど）を、指定されたLLMのコンテキストウィンドウサイズに応じて自動的に分割し、各チャンクを分析します。その後、すべての中間分析結果を統合し、最終的なサマリーレポートを生成するGo製のコマンドラインツールです。

#### **2. 機能要件**

*   **データ入力:**
    *   分析対象のファイルパスをコマンドライン引数として受け取ります。
    *   入力形式はプレーンテキストまたはJSONL形式をサポートします。

*   **LLM設定:**
    *   設定ファイル（例: `config.yaml`）または環境変数で、複数のLLMエンドポイントを定義できます。
    *   各エンドポイント設定には以下の情報を含みます。
        *   `name`: 設定の識別名 (例: `openai_gpt4`, `local_mistral`)
        *   `endpoint_url`: APIエンドポイントのURL
        *   `api_key_env`: APIキーが格納されている環境変数名 (例: `OPENAI_API_KEY`)
        *   `model`: 使用するモデル名 (例: `gpt-4o`, `llama3-70b`)
        *   `context_window_size`: モデルの最大コンテキストウィンドウ（トークン数）
        *   `chunk_size`: データ分割時の各チャンクの最大トークン数。`context_window_size`より小さい必要があります。

*   **プロンプト設定:**
    *   データ分析用のプロンプト（各チャンクに適用）をファイルから読み込みます。
    *   最終レポート生成用のプロンプト（中間結果の要約に適用）をファイルから読み込みます。

*   **処理フロー:**
    1.  **初期化:** 設定ファイルとコマンドライン引数を読み込みます。
    2.  **データ読み込みと分割:**
        *   入力ファイルを読み込みます。
        *   Go言語用の`tiktoken`ライブラリを利用してテキストをトークンに変換し、指定された`chunk_size`に基づいてデータを分割します。
        *   JSONLの場合は、複数行をまとめて1チャンクとしますが、1行が`chunk_size`を超える場合はエラーとします。
    3.  **並列分析 (Map処理):**
        *   分割された各データチャンクに対して、Goroutineを用いて並列でLLM APIを呼び出し、分析を実行します。
        *   各API呼び出しでは、ユーザー指定の「データ分析用プロンプト」とデータチャンクをLLMに送信します。
        *   LLMからの分析結果（テキスト）を一時ディレクトリに個別のファイルとして保存します（例: `chunk_1.txt`, `chunk_2.txt`, ...）。
    4.  **結果の集約 (Reduce処理):**
        *   すべての中間分析結果ファイルを読み込み、内容を結合します。
        *   結合した中間結果とユーザー指定の「最終レポート生成用プロンプト」を使い、再度LLM APIを呼び出します。
        *   **再帰的要約:** もし結合した中間結果のトークン数がコンテキストウィンドウを超える場合は、中間結果自体をさらに分割し、この集約ステップを再帰的に繰り返します。
    5.  **出力:**
        *   最終的な分析レポートを標準出力に表示するか、指定されたファイルに出力します。

*   **一時ファイル管理:**
    *   `--temp-dir`フラグで一時ディレクトリのパスを指定できます。
    *   指定がない場合、OSの一時ディレクトリ内にランダムな名前のディレクトリを自動で作成します。
    *   `--keep-temp-dir`フラグが指定されていない限り、処理完了後に自動作成した一時ディレクトリはクリーンアップ（削除）します。

#### **3. コマンドラインインターフェース（CLI）設計案**

```bash
go-data-analyzer [flags] <input_file_path>
```

**フラグ:**

*   `--config, -c` (string): 設定ファイルのパス (デフォルト: `config.yaml`)
*   `--endpoint-name, -e` (string): 使用するLLMエンドポイントの名前（設定ファイルで定義）
*   `--analysis-prompt-file` (string): データ分析用プロンプトが書かれたファイルのパス **(必須)**
*   `--summary-prompt-file` (string): 最終レポート生成用プロンプトが書かれたファイルのパス **(必須)**
*   `--output, -o` (string): 出力ファイルのパス（指定がなければ標準出力）
*   `--temp-dir` (string): 中間ファイルを保存する一時ディレクトリのパス
*   `--keep-temp-dir` (bool): 処理終了後も一時ディレクトリを保持するかどうか
*   `--verbose, -v` (bool): 詳細なログ（どのチャンクを処理しているかなど）を出力する

---

### **開発計画**

以下のマイルストーンに沿って開発を進めます。

1.  **フェーズ1: プロジェクト基盤の構築 (完了)**
    *   [x] Goプロジェクトの初期化 (`go mod init`)。
    *   [x] CLIフレームワーク `cobra` を導入し、上記フラグの定義と基本的な引数処理を実装。
    *   [x] `Viper` などのライブラリを使い、`config.yaml` の読み込み処理を実装。
    *   [x] OpenAI互換APIを呼び出すための基本的なHTTPクライアントを実装。

2.  **フェーズ2: データ分割と単一分析機能 (完了)**
    *   [x] `tiktoken` ライブラリを導入し、テキストを指定トークン数で分割するロジックを実装。
    *   [x] JSONL形式を考慮した分割ロジックを実装。
    *   [x] 1つのデータチャンクとプロンプトを使い、LLMで分析を実行して結果を返すコア機能を実装。

3.  **フェーズ3: 並列処理と中間ファイル管理 (完了)**
    *   [x] Goroutineと`sync.WaitGroup`を利用して、複数のデータチャンクを並列で分析する処理を実装。
    *   [x] 分析結果を一時ファイルに保存・管理する機能を実装。
    *   [x] `--temp-dir`, `--keep-temp-dir` フラグに応じた一時ディレクトリの作成・削除処理を実装。

4.  **フェーズ4: 結果の集約と最終レポート生成 (完了)**
    *   [x] すべての中間ファイルを読み込み、結合する処理を実装。
    *   [x] 結合した中間結果とサマリープロンプトを使い、最終レポートを生成する機能（Reduce処理）を実装。
    *   [x] 中間結果がコンテキストウィンドウを超える場合の再帰的要約ロジックを実装。

5.  **フェーズ5: テスト、ドキュメント、リファクタリング (完了)**
    *   [x] 主要機能に対するユニットテストと、ツール全体を通した結合テストを作成。
    *   [x] `README.md` に、ツールの目的、インストール方法、設定方法、CLIの使用例などを詳細に記述。
    *   [x] エラーハンドリングを強化し、全体的なコードの可読性と保守性を向上。
